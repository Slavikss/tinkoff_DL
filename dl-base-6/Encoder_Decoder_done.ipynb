{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets nltk"
      ],
      "metadata": {
        "id": "Vr8y4W8LS_NG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder and Decoder\n",
        "\n",
        "\n",
        "Всем привет! В этом занятии мы обсудим две главные архитектуры в текстовых данных Encoder и Decoder"
      ],
      "metadata": {
        "id": "_0bx7vN1ROBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5fGtk0rRGgp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import nltk\n",
        "import torchvision\n",
        "import datasets\n",
        "\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder. Task: Part-of-Speach"
      ],
      "metadata": {
        "id": "8_x6DVSyRXtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of dataset (https://huggingface.co/datasets/conll2003)"
      ],
      "metadata": {
        "id": "hGCgvpC4RdRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_dataset = datasets.load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "KGAxCj-hLNpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_dataset"
      ],
      "metadata": {
        "id": "w-mnZOiTLWEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "4-fJsCRbLmoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = {token for sentence in conll_dataset[\"train\"][\"tokens\"] for token in sentence}\n",
        "all_pos_tags = {tags for sentence_pos in conll_dataset[\"train\"][\"pos_tags\"] for tags in sentence_pos}"
      ],
      "metadata": {
        "id": "EN9cyZPsLyxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_words), len(all_pos_tags)"
      ],
      "metadata": {
        "id": "z00roBhmLmff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example with nltk (https://www.nltk.org/book/ch05.html)\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "zamzTAXcRbx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = nltk.tokenize.WordPunctTokenizer()"
      ],
      "metadata": {
        "id": "IOyYRo82hNcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am fine...\"\n",
        "nltk.pos_tag(tokenizer.tokenize(text))"
      ],
      "metadata": {
        "id": "ikqbEY01Lakj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(conll_dataset[\"validation\"][\"tokens\"][0])"
      ],
      "metadata": {
        "id": "v_rrg5h5Laid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conll_dataset[\"validation\"][\"pos_tags\"][0]"
      ],
      "metadata": {
        "id": "cnp0AzkALaf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GK8bAdGjhtdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhifaqKjhtbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0o3u1SvhtYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Dataset and Dataloader out of conll"
      ],
      "metadata": {
        "id": "F_TYYhuhLadM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConllDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, all_words):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = {\n",
        "            w: idx + 16\n",
        "            for idx, w in enumerate(all_words)\n",
        "        }\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = [self.tokenizer[w] for w in self.dataset[\"tokens\"][idx]]\n",
        "        tags = self.dataset[\"pos_tags\"][idx]\n",
        "        return tokens, tags\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset[\"tokens\"])"
      ],
      "metadata": {
        "id": "H5_d_rjAOB7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ConllDataset(conll_dataset[\"train\"][:128], all_words) # only 128 datapoints "
      ],
      "metadata": {
        "id": "3m74IW5yOB5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0], train_dataset[1]"
      ],
      "metadata": {
        "id": "QuW3XI5Si2CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[4993, 10341, 8947, 20324, 14005, 4188, 15844, 12482, 15792], [20263, 11688]])"
      ],
      "metadata": {
        "id": "RlmIQBc_oliQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(items):\n",
        "    tokens = [torch.tensor(i[0]) for i in items]\n",
        "    tags = [torch.tensor(i[1]) for i in items]\n",
        "    packed_tokens = torch.nn.utils.rnn.pack_sequence(tokens, enforce_sorted=False)\n",
        "    packed_tags = torch.nn.utils.rnn.pack_sequence(tags, enforce_sorted=False)\n",
        "    return packed_tokens, packed_tags"
      ],
      "metadata": {
        "id": "PEstKxcejcsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    collate_fn=collate_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "qctPIx3FOB2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "packed_tokens, packed_tags = next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "OpH92QaZjGOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "packed_tokens"
      ],
      "metadata": {
        "id": "e87oXdb0k6vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3> 18481 13798\n",
        "# 0> 4993 10341\n",
        "# 1> 20263 11688\n",
        "# 2> 7471 11511"
      ],
      "metadata": {
        "id": "exUpTr8XozeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_packed_tokens = torch.nn.utils.rnn.pad_packed_sequence(packed_tokens)"
      ],
      "metadata": {
        "id": "IQmQyOPdkoKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_pad_packed_tokens = pad_packed_tokens[0].reshape(-1, 4, 1)\n",
        "emb_pad_packed_tokens"
      ],
      "metadata": {
        "id": "CDJ461felh_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.utils.rnn.pack_padded_sequence(emb_pad_packed_tokens, pad_packed_tokens[1], enforce_sorted=False)"
      ],
      "metadata": {
        "id": "wpVPA0t_lQHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try to code it on RNN"
      ],
      "metadata": {
        "id": "M6_oMngaReyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN4POS(torch.nn.Module):\n",
        "    def __init__(self, num_words, num_tags, hidden_size: int = 64, num_layers: int = 1, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = torch.nn.Embedding(num_words, hidden_size)\n",
        "        self.rnn = torch.nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout)\n",
        "        self.cls_head = torch.nn.Linear(hidden_size, num_tags)\n",
        "\n",
        "    def forward(self, input_ids, length_inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: Torch.Tensor, shape: (seq_length, batch_size, hidden_size)\n",
        "\n",
        "        To understand inputs for this module, please check rnn_padding:\n",
        "            - https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html\n",
        "            - https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html\n",
        "        \"\"\"\n",
        "        embs = self.embeddings(input_ids)\n",
        "\n",
        "        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(embs, length_inputs, enforce_sorted=False)\n",
        "        rnn_outputs, _ = self.rnn(packed_sequences)\n",
        "        unpacked_sequences, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_outputs)\n",
        "\n",
        "        return self.cls_head(unpacked_sequences)"
      ],
      "metadata": {
        "id": "aBCR4h7iLpcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN4POS(len(all_words), len(all_pos_tags))\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "metadata": {
        "id": "-xylrxxfLpaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, batch in enumerate(train_dataloader):\n",
        "    inputs, labels = batch\n",
        "    inputs, inputs_length = torch.nn.utils.rnn.pad_packed_sequence(inputs)\n",
        "    labels, _ = torch.nn.utils.rnn.pad_packed_sequence(labels)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs, inputs_length)\n",
        "    num_classes = outputs.size(-1)\n",
        "    loss = criterion(outputs.view(-1, num_classes), labels.view(-1))\n",
        "    optimizer.step()\n",
        "    print(f\"{idx:>10}: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "qV61uYJMLpXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete everythin and run torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "hAbbnL7uLIK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "del optimizer\n",
        "del loss\n",
        "del train_dataloader\n",
        "del train_dataset\n",
        "del batch\n",
        "del inputs\n",
        "del labels\n",
        "del loss"
      ],
      "metadata": {
        "id": "LGmvdzUMOdpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "MY_hnJFKPHD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder. Text Generation"
      ],
      "metadata": {
        "id": "FHl7ZdTsRlHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look at dataset (https://huggingface.co/datasets/rotten_tomatoes)"
      ],
      "metadata": {
        "id": "qjeUOmWARn_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rt_dataset = datasets.load_dataset(\"rotten_tomatoes\")"
      ],
      "metadata": {
        "id": "Zg7Vhok2PZlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rt_dataset"
      ],
      "metadata": {
        "id": "lEmZ2BlpQVsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rt_dataset[\"train\"][\"text\"][0]"
      ],
      "metadata": {
        "id": "6K-oXXz8p8y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = {w for s in rt_dataset[\"train\"][\"text\"] for w in s.split(\" \")}"
      ],
      "metadata": {
        "id": "56t00czlSMJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BOS > 1\n",
        "# EOS > 2\n",
        "# pad"
      ],
      "metadata": {
        "id": "aSeAX0OdSMHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create torch dataset"
      ],
      "metadata": {
        "id": "laP8AGP5QVph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, all_words):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = {\n",
        "            w: idx + 16\n",
        "            for idx, w in enumerate(all_words)\n",
        "        }\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # better convert in tensor\n",
        "        tokens = [1] + [self.tokenizer[w] for w in self.dataset[\"text\"][idx].split(\" \")] + [2]\n",
        "        return torch.tensor(tokens)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset[\"text\"])"
      ],
      "metadata": {
        "id": "SCD816iVQVnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = RTDataset(rt_dataset[\"train\"], all_words) # only 128 datapoints "
      ],
      "metadata": {
        "id": "gcDrpPA-QUke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(items):\n",
        "    packed_tokens = torch.nn.utils.rnn.pack_sequence(items, enforce_sorted=False)\n",
        "    return packed_tokens\n",
        "\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "sZmMBOt0qpj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))"
      ],
      "metadata": {
        "id": "6CkbiDrUqph4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGJCb-yUqpgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRzcrxxNqpd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mR7sSwUYqpcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WsnQw8JPqpaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write down rnn model"
      ],
      "metadata": {
        "id": "KVFFYfgmRnyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN4GEN(torch.nn.Module):\n",
        "    def __init__(self, num_words, hidden_size: int = 256, num_layers: int = 6, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embeddings = torch.nn.Embedding(num_words, hidden_size)\n",
        "        self.rnn = torch.nn.LSTM(hidden_size, hidden_size, num_layers, dropout=dropout)\n",
        "\n",
        "    def forward(self, input_ids, length_inputs):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: Torch.Tensor, shape: (seq_length, batch_size)\n",
        "\n",
        "        To understand inputs for this module, please check rnn_padding:\n",
        "            - https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html\n",
        "            - https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html\n",
        "        \"\"\"\n",
        "        embs = self.embeddings(input_ids)\n",
        "\n",
        "        packed_sequences = torch.nn.utils.rnn.pack_padded_sequence(embs, length_inputs, enforce_sorted=False)\n",
        "        rnn_outputs, _ = self.rnn(packed_sequences)\n",
        "        unpacked_sequences, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_outputs)\n",
        "\n",
        "        # unpacked_sequences (seq_length, batch_size, hidden_size)\n",
        "        # self.embeddings.weight (num_words, hidden_size)\n",
        "        # want output: (seq_length, batch_size, num_words)\n",
        "\n",
        "        return unpacked_sequences @ self.embeddings.weight.T\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_one_token(self, input_ids):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_ids: Torch.Tensor, shape: (seq_length, 1)\n",
        "        \"\"\"\n",
        "        embs = self.embeddings(input_ids)\n",
        "        rnn_outputs, _ = self.rnn(embs)\n",
        "        return rnn_outputs[-1] @ self.embeddings.weight.T"
      ],
      "metadata": {
        "id": "YzSGmgGSPY8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofcduAJGt1gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN4GEN(len(all_words) + 16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
      ],
      "metadata": {
        "id": "knUGrNC7R5tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.predict_one_token(torch.tensor([1, 10]))\n",
        "output.size()"
      ],
      "metadata": {
        "id": "pln-5Qynt5cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_words) + 16"
      ],
      "metadata": {
        "id": "C9vMH7qxuCyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(output, dim=0)"
      ],
      "metadata": {
        "id": "sAjoorZSuCwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-Cd4v5BuCtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, batch in enumerate(train_dataloader):\n",
        "    inputs_ = batch\n",
        "    inputs_, inputs_length_ = torch.nn.utils.rnn.pad_packed_sequence(inputs_)\n",
        "    inputs, labels = inputs_[:-1], inputs_[1:]\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs, inputs_length_ - 1)\n",
        "    loss = criterion(outputs.view(-1, len(all_words) + 16), labels.view(-1))\n",
        "    optimizer.step()\n",
        "    print(f\"{idx:>10}: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "iCNIb21QR5v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test it with different generation strategies"
      ],
      "metadata": {
        "id": "cZQwTYZURnWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greed_search(model):\n",
        "    input = torch.tensor([1])\n",
        "    while input.size(0) < 16:\n",
        "        output = model.predict_one_token(input)\n",
        "        max_token = torch.max(output, dim=0)[1]\n",
        "        input = torch.concat([input, max_token.reshape(1)])\n",
        "        if max_token == 2:\n",
        "            break\n",
        "    return input"
      ],
      "metadata": {
        "id": "4IRWBrqLQzMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greed_search(model)"
      ],
      "metadata": {
        "id": "8gqUD7Baunvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detokenizer = {idx: w for w, idx in train_dataset.tokenizer.items()}"
      ],
      "metadata": {
        "id": "BrLt5KkAuqFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[detokenizer.get(i, \"\") for i in [    1,  5407,  6330,  3685,  4603, 16354,  3314, 18948,  1396,  4150,\n",
        "         3761, 12143, 12163,  4249, 14375, 14148]]"
      ],
      "metadata": {
        "id": "CfsDlxrkuqCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.multinomial(torch.tensor([0.1, 0.3, 0.6]), 1)"
      ],
      "metadata": {
        "id": "uduBwE8Cup_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_sample(model):\n",
        "    input = torch.tensor([1])\n",
        "    while input.size(0) < 16:\n",
        "        output = model.predict_one_token(input)\n",
        "        probs = torch.softmax(output, dim=0)\n",
        "        token = torch.multinomial(probs, 1)\n",
        "        input = torch.concat([input, token])\n",
        "        if token == 2:\n",
        "            break\n",
        "    return input"
      ],
      "metadata": {
        "id": "I485ZyRkQzJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_k_sample(model)"
      ],
      "metadata": {
        "id": "4poY68fkvz7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[detokenizer.get(i, \"\") for i in [    1,    60, 18108,  3954,  3764,  4819, 14263, 18427, 14874,   995,\n",
        "        12968, 12086,  3397,  9754, 16320, 10100]]"
      ],
      "metadata": {
        "id": "h8x2yvMjv2cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check generation"
      ],
      "metadata": {
        "id": "EgH2LUtgQzDb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}