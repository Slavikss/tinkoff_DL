{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pytorch_lightning==1.8.3 pytorch_metric_learning==1.6.3\n",
        "! pip install faiss-gpu\n",
        "! apt install libomp-dev"
      ],
      "metadata": {
        "id": "Xcu4yAQCHetE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPLPTlAfGmMp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torchvision\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "# Restart the environment if crashes.\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "from collections import defaultdict\n",
        "py.init_notebook_mode()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Семинар 8. Metric Learning.\n",
        "В данном семинаре мы реализуем несколько подходов Metric Learning, а также визуализируем их работу. Будем обучаться на датасете [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Это небольшой датасет из 10-ти категорий, на котором мы быстро сможем получать результаты."
      ],
      "metadata": {
        "id": "sbqEamOeeQ-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "uoumAxinTglQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Вспомогательные классы для датасета и семплера. На семинаре сюда заглядывать не придётся.\n",
        "\"\"\"\n",
        "\n",
        "class TransformDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Apply transform to the dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset, transform):\n",
        "        super().__init__()\n",
        "        self._transform = transform\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get element of the dataset.\"\"\"\n",
        "        item = self.dataset[index]\n",
        "        image = self._transform(item[0])\n",
        "        return (image,) + item[1:]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "class UniformLabelsSampler:\n",
        "    \"\"\"Sample labels with equal probabilities.\"\"\"\n",
        "    def __init__(self, labels, labels_per_batch, num_batches):\n",
        "        self._labels = set(labels)\n",
        "        self._labels_per_batch = labels_per_batch\n",
        "        self._num_batches = num_batches\n",
        "        if len(self._labels) < labels_per_batch:\n",
        "            raise ValueError(\"Can't sample equal number of labels. Batch is too large.\")\n",
        "\n",
        "    def __iter__(self):\n",
        "        labels = list(self._labels)\n",
        "        i = 0\n",
        "        for _ in range(self._num_batches):\n",
        "            if i + self._labels_per_batch > len(labels):\n",
        "                random.shuffle(labels)\n",
        "                i = 0\n",
        "            yield list(labels[i:i + self._labels_per_batch])\n",
        "            i += self._labels_per_batch\n",
        "\n",
        "\n",
        "class ShuffledClassBalancedBatchSampler(torch.utils.data.Sampler):\n",
        "    \"\"\"Sampler which extracts balanced number of samples for each class.\n",
        "\n",
        "    Args:\n",
        "        data_source: Source dataset. Labels field must be implemented.\n",
        "        batch_size: Required batch size.\n",
        "        samples_per_class: Number of samples for each class in the batch.\n",
        "            Batch size must be a multiple of samples_per_class.\n",
        "        uniform: If true, sample labels uniformly. If false, sample labels according to frequency.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_source, batch_size, samples_per_class):\n",
        "        if batch_size > len(data_source):\n",
        "            raise ValueError(\"Dataset size {} is too small for batch size {}.\".format(\n",
        "                len(data_source), batch_size))\n",
        "        if batch_size % samples_per_class != 0:\n",
        "            raise ValueError(\"Batch size must be a multiple of samples_per_class, but {} != K * {}.\".format(\n",
        "                batch_size, samples_per_class))\n",
        "\n",
        "        self._data_source = data_source\n",
        "        self._batch_size = batch_size\n",
        "        self._labels_per_batch = self._batch_size // samples_per_class\n",
        "        self._samples_per_class = samples_per_class\n",
        "        labels = [i[1] for i in data_source]\n",
        "        self._label_sampler = UniformLabelsSampler(labels, self._labels_per_batch,\n",
        "                                                   num_batches=len(self))\n",
        "\n",
        "        by_label = defaultdict(list)\n",
        "        for i, label in enumerate(labels):\n",
        "            by_label[label].append(i)\n",
        "        self._by_label = list(by_label.values())\n",
        "        if self._labels_per_batch > len(self._by_label):\n",
        "            raise ValueError(\"Can't sample {} classes from dataset with {} classes.\".format(\n",
        "                self._labels_per_batch, len(self._by_label)))\n",
        "\n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return self._batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        for labels in self._label_sampler:\n",
        "            batch = []\n",
        "            for label in labels:\n",
        "                batch.extend(np.random.choice(self._by_label[label], size=self._samples_per_class, replace=True))\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        num_samples = len(self._data_source)\n",
        "        num_batches = num_samples // self._batch_size\n",
        "        return num_batches"
      ],
      "metadata": {
        "id": "l-ANMv9tVEix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Функции для визуализации эмбеддингов в 2D и 3D. Можно ознакомиться с кодом после семинара, если понравятся картинки.\n",
        "\"\"\"\n",
        "\n",
        "LAYOUT = go.Layout(\n",
        "    title='CIFAR100 3D embeddings',\n",
        "    scene=dict(\n",
        "        xaxis=dict(\n",
        "            gridcolor='rgb(255, 255, 255)',\n",
        "            zerolinecolor='rgb(255, 255, 255)',\n",
        "            showbackground=True,\n",
        "            backgroundcolor='rgb(230, 230,230)'\n",
        "        ),\n",
        "        yaxis=dict(\n",
        "            gridcolor='rgb(255, 255, 255)',\n",
        "            zerolinecolor='rgb(255, 255, 255)',\n",
        "            showbackground=True,\n",
        "            backgroundcolor='rgb(230, 230,230)'\n",
        "        ),\n",
        "        zaxis=dict(\n",
        "            gridcolor='rgb(255, 255, 255)',\n",
        "            zerolinecolor='rgb(255, 255, 255)',\n",
        "            showbackground=True,\n",
        "            backgroundcolor='rgb(230, 230,230)'\n",
        "        )\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "def visualize_embeddings(embs, labels):\n",
        "    if embs.shape[1] == 2:\n",
        "        _visualize_2d(embs, labels)\n",
        "    elif embs.shape[1] == 3:\n",
        "        _visualize_3d(embs, labels)\n",
        "\n",
        "\n",
        "def _visualize_2d(embs, labels):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for l in np.unique(labels):\n",
        "        plt.scatter(*embs[labels == l].T, alpha=0.5)\n",
        "\n",
        "\n",
        "def create_spferical_surface(colorscale):\n",
        "    pi = np.pi\n",
        "    cos = np.cos\n",
        "    sin = np.sin\n",
        "    phi, theta = np.mgrid[0.0:pi:50j, 0.0:2.0*pi:50j]\n",
        "    r = 1.0\n",
        "    x = r*sin(phi)*cos(theta)\n",
        "    y = r*sin(phi)*sin(theta)\n",
        "    z = r*cos(phi)\n",
        "    surface = go.Surface(\n",
        "        x=x, y=y, z=z,\n",
        "        colorscale=colorscale,\n",
        "        showscale=False\n",
        "    )\n",
        "    return surface\n",
        "\n",
        "\n",
        "def create_embeddings_scatter(embeddings):\n",
        "    scatter = go.Scatter3d(\n",
        "        x=embeddings.T[0],\n",
        "        y=embeddings.T[1],\n",
        "        z=embeddings.T[2],\n",
        "        mode='markers',\n",
        "        marker_size=2.5,\n",
        "    )\n",
        "    return scatter\n",
        "\n",
        "\n",
        "def _visualize_3d(embs, labels):\n",
        "    embs = embs / (np.sqrt((embs ** 2).sum(-1))[..., np.newaxis] * (1 - 0.02))\n",
        "    surface = create_spferical_surface(\"greys\")\n",
        "\n",
        "    classes = np.unique(labels)\n",
        "    embeddings = []\n",
        "    for c in classes:\n",
        "        class_embeddings = embs[labels == c]\n",
        "        embeddings.append(create_embeddings_scatter(class_embeddings))\n",
        "            \n",
        "    data = [surface, *embeddings]\n",
        "\n",
        "    fig = go.Figure(data=data, layout=LAYOUT)\n",
        "    py.iplot(fig)\n",
        "    fig.write_html(\"./3dvis.html\")"
      ],
      "metadata": {
        "id": "0PSZLJWaO-ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18Backbone(torch.nn.Module):\n",
        "    def __init__(self, dim=2):\n",
        "        # TODO in task 1\n",
        "        super().__init__()\n",
        "        self.model = getattr(torchvision.models, \"resnet18\")(pretrained=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.model(input)\n",
        "        return x"
      ],
      "metadata": {
        "id": "qphIzr6xOoOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_triplets(batch):\n",
        "    # TODO in task 2\n",
        "\n",
        "\n",
        "def test_triplets():\n",
        "  batch = torch.tensor(np.arange(256)), torch.tensor(np.array([[i] * (256 // 8) for i in range(8)]).flatten())\n",
        "  triplets = generate_triplets(batch)\n",
        "  assert all([len(e[0]) == len(batch[0]) for e in triplets]), \"Number of triplets shold be equal to batch size.\"\n",
        "  assert all([len(e[1]) == len(batch[1]) for e in triplets]), \"Number of triplets shold be equal to batch size.\"\n",
        "  assert all(triplets[0][1] == triplets[1][1]), \"Anchor's label should be equal to positive's label.\"\n",
        "  assert all(triplets[0][1] != triplets[2][1]), \"Anchor's label shouldn't be equal to negative's label.\"\n",
        "  assert all([all(batch[1][e[0]] == e[1]) for e in triplets]), \"Incorrect labels in triplets.\"\n",
        "  assert all([isinstance(e[0], torch.Tensor) and isinstance(e[0], torch.Tensor) for e in triplets]), \"Output arrays should be torch.Tensor type.\"\n",
        "test_triplets()"
      ],
      "metadata": {
        "id": "SCYX3y51OxIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TriptetLoss:\n",
        "    def __init__(self, margin=10):\n",
        "        # TODO in task 3\n",
        "    def __call__(self, triplets):\n",
        "        # TODO in task 3"
      ],
      "metadata": {
        "id": "Fm62rUbhO0q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CosFaceClassifier(torch.nn.Linear):\n",
        "    def __init__(self, in_features, out_features, scale=64.0, margin=0.35):\n",
        "        # TODO in task 4\n",
        "    \n",
        "    def forward(self, input, label):\n",
        "        # TODO in task 4\n",
        "\n",
        "\n",
        "def test_cosface():\n",
        "    classifier = CosFaceClassifier(2, 2, scale=2., margin=.5)\n",
        "    classifier.weight = torch.nn.Parameter(torch.Tensor([[1., 2.], [3., 4.]]))\n",
        "    inputs = torch.Tensor([[1.0, 0.0], [0.0, 1.0]])\n",
        "    labels = torch.Tensor([0, 1])\n",
        "    logits = classifier(inputs, labels)\n",
        "    true_cosine = np.array([[1 / np.sqrt(5), 3 / 5], [2 / np.sqrt(5), 4 / 5]])\n",
        "    true_logits = 2 * (true_cosine - np.eye(2) * 0.5)\n",
        "    assert np.allclose(logits.detach().numpy(), true_logits)\n",
        "\n",
        "test_cosface()"
      ],
      "metadata": {
        "id": "dlAs2plWO4Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Основной код пайплайна на фреймворке Pytorch Lightning. Разберём на семинаре.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "CRITERIONS = {\n",
        "    \"ce\": torch.nn.CrossEntropyLoss,\n",
        "    \"triplet\": None\n",
        "}\n",
        "\n",
        "\n",
        "CLASSIFIERS = {\n",
        "    \"linear\": torch.nn.Linear,\n",
        "    \"cosface\": None\n",
        "}\n",
        "\n",
        "\n",
        "class CIFAR10Module(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self._config = config\n",
        "        self.embedder = ResNet18Backbone(dim=config[\"dim\"])\n",
        "        self.classifier = self.get_classifier()\n",
        "        self.criterion = self.get_criterion()\n",
        "        self.recall_calculator = AccuracyCalculator(\n",
        "            include=(\"precision_at_1\", \"mean_average_precision_at_r\"), k=\"max_bin_count\"\n",
        "        )\n",
        "  \n",
        "    def train_dataset(self):\n",
        "        CIFAR_trainset = torchvision.datasets.CIFAR10(\n",
        "            root='./data', train=True, download=True\n",
        "        )\n",
        "        CIFAR_testset = torchvision.datasets.CIFAR10(\n",
        "            root='./data', train=False, download=True\n",
        "        )\n",
        "        transform = torchvision.transforms.Compose(\n",
        "            [torchvision.transforms.AutoAugment(torchvision.transforms.AutoAugmentPolicy.CIFAR10),\n",
        "            torchvision.transforms.ToTensor()]\n",
        "        )\n",
        "        return TransformDataset(CIFAR_trainset, transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        dataset = self.train_dataset()\n",
        "        params = self._config[\"dataset_params\"]\n",
        "        if \"use_balanced_sampler\" in params and params[\"use_balanced_sampler\"]:\n",
        "            sampler = ShuffledClassBalancedBatchSampler(\n",
        "                dataset, params[\"batch_size\"], params[\"samples_per_class\"]\n",
        "            )\n",
        "            return torch.utils.data.DataLoader(\n",
        "                dataset, batch_sampler=sampler, num_workers=12\n",
        "            )\n",
        "        else:\n",
        "            return torch.utils.data.DataLoader(\n",
        "                dataset, params[\"batch_size\"], num_workers=12\n",
        "            )\n",
        "    \n",
        "    def test_dataset(self):\n",
        "        CIFAR_trainset = torchvision.datasets.CIFAR10(\n",
        "            root='./data', train=True, download=True, \n",
        "            transform=torchvision.transforms.ToTensor()\n",
        "        )\n",
        "        CIFAR_testset = torchvision.datasets.CIFAR10(\n",
        "            root='./data', train=False, download=True,\n",
        "            transform=torchvision.transforms.ToTensor()\n",
        "        )\n",
        "        return CIFAR_testset\n",
        "  \n",
        "    def test_dataloader(self):\n",
        "        dataset = self.test_dataset()\n",
        "        params = self._config[\"dataset_params\"]\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset, batch_size = params[\"batch_size\"], num_workers=12\n",
        "        )\n",
        "  \n",
        "    def val_dataloader(self):\n",
        "        return self.test_dataloader()\n",
        "  \n",
        "    def configure_optimizers(self):\n",
        "        params = self._config[\"optimizer_params\"]\n",
        "        optimizer = torch.optim.SGD(self.parameters(), **params)\n",
        "        return optimizer\n",
        "    \n",
        "    def get_criterion(self):\n",
        "        criterion_type = self._config[\"criterion_type\"]\n",
        "        params = self._config[\"criterion_params\"] if \"criterion_params\" in self._config else {}\n",
        "        return CRITERIONS[criterion_type](**params)\n",
        "    \n",
        "    def get_classifier(self):\n",
        "        classifier_type = self._config[\"classifier_type\"]\n",
        "        params = self._config[\"classifier_params\"] if \"classifier_params\" in self._config else {}\n",
        "        return CLASSIFIERS[classifier_type](self.embedder.model.fc.out_features, 10, **params)\n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        embeddings = self.embedder(images)\n",
        "        if isinstance(self.criterion, torch.nn.CrossEntropyLoss):\n",
        "            if isinstance(self.classifier, CosFaceClassifier):\n",
        "                logits = self.classifier(embeddings, labels)\n",
        "            else:\n",
        "                logits = self.classifier(embeddings)\n",
        "            loss = self.criterion(logits, labels)\n",
        "        elif isinstance(self.criterion, TriptetLoss):\n",
        "            triplets = generate_triplets((embeddings, labels))\n",
        "            loss = self.criterion(triplets)\n",
        "        self.log(\"loss\", loss)\n",
        "        return {\"loss\": loss}\n",
        "    \n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        embeddings = self.embedder(images)\n",
        "        return {\"embeddings\": embeddings.cpu(), \"labels\": labels.cpu()}\n",
        "    \n",
        "    def test_epoch_end(self, outputs) -> None:\n",
        "        embeddings = np.vstack([b[\"embeddings\"].numpy() for b in outputs])\n",
        "        labels = np.hstack([b[\"labels\"].numpy() for b in outputs])\n",
        "        visualize_embeddings(embeddings, labels)\n",
        "        if embeddings.shape[1] == 3:\n",
        "            embeddings = embeddings / np.sqrt((embeddings ** 2).sum(-1))[..., np.newaxis]\n",
        "        metrics = self.recall_calculator.get_accuracy(\n",
        "            embeddings, embeddings,\n",
        "            labels, labels,\n",
        "            embeddings_come_from_same_source=True\n",
        "        )\n",
        "        self.log(\"r_at_one\", metrics[\"precision_at_1\"])\n",
        "        self.log(\"map_at_r\", metrics[\"mean_average_precision_at_r\"])\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.test_step(batch, batch_idx)\n",
        "    \n",
        "    def validation_epoch_end(self, outputs) -> None:\n",
        "        embeddings = np.vstack([b[\"embeddings\"].numpy() for b in outputs])\n",
        "        labels = np.hstack([b[\"labels\"].numpy() for b in outputs])\n",
        "        metrics = self.recall_calculator.get_accuracy(\n",
        "            embeddings, embeddings,\n",
        "            labels, labels,\n",
        "            embeddings_come_from_same_source=True\n",
        "        )\n",
        "        self.log(\"val_r_at_one\", metrics[\"precision_at_1\"])\n",
        "        self.log(\"val_map_at_r\", metrics[\"mean_average_precision_at_r\"])"
      ],
      "metadata": {
        "id": "C9yQuXAsGsrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1. Разминка.\n",
        "Мы хотим посмотреть на пространство эмбеддингов, которое формирует обычный классификатор, \n",
        "обученный с CE. В классе `Resnet18Backbone` добавьте возможность изменять выходную размерность последнего линейного слоя. Поставьте её равной 2. Это понадобится нам для визуализации эмбеддингов.\n",
        "\n",
        "Запустите пайплайн и убедитесь, что всё работает. Должны появиться метрики на тесте и визуализация эмбеддингов."
      ],
      "metadata": {
        "id": "FCZdM4B7uYfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All logs here.\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs/"
      ],
      "metadata": {
        "id": "2mSa_50zbOcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"dim\": 2,\n",
        "    \"criterion_type\": \"ce\",\n",
        "    \"classifier_type\": \"linear\",\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.005,\n",
        "        \"momentum\": 0.9\n",
        "    },\n",
        "    \"dataset_params\": {\n",
        "        \"batch_size\": 256\n",
        "    }\n",
        "}\n",
        "module = CIFAR10Module(config)\n",
        "logger = pl.loggers.TensorBoardLogger(\"./logs\", name='ce')\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    logger=logger,\n",
        "    log_every_n_steps=10,\n",
        "    max_epochs=10\n",
        ")\n",
        "trainer.fit(module)\n",
        "trainer.test()"
      ],
      "metadata": {
        "id": "AKq-Pp45HUg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2. Генерируем триплеты.\n",
        "Реализуйте функцию, которая генерирует триплеты для дальнейшего обучения с Triplet Loss:\n",
        "```\n",
        "generate_triplets((images[B x 3 x 32 x 32], labels[B]))\n",
        "|\n",
        "v\n",
        "(anchor_images[B x 3 x 32 x 32], anchor_labels[B]),\n",
        "(positive_images[B x 3 x 32 x 32], positive_labels[B]),\n",
        "(negative_images[B x 3 x 32 x 32], negative_labels[B])\n",
        "```\n",
        "B - batch size. Метки anchor и positive совпадают, anchor и negative - различаются. Проверьте, что тесты не падают.\n"
      ],
      "metadata": {
        "id": "tOQRpyIovpSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 3. Triplet Loss.\n",
        "Итак, мы умеем семплировать триплеты. В этом задании нужно реализовать Triplet Loss:\n",
        "\\begin{equation}\n",
        "L_{\\text {triplet }}=\\left[d_{a p}-d_{a n}+m\\right]_{+}\n",
        "\\end{equation}\n",
        "m - margin, $d_{a p}$ - L2 расстояние между anchor и positive, $d_{a n}$ - L2 расстояние между anchor и negative.\n",
        "Предлагается работать с заготовкой класса `TripletLoss`. Не забудьте про margin и усреднить лосс по батчу.\n",
        "Обучите модель с новым лоссом."
      ],
      "metadata": {
        "id": "kuyOmvZLvyuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"dim\": 2,\n",
        "    \"criterion_type\": \"triplet\",\n",
        "    \"criterion_params\": {\n",
        "        \"margin\": 1.0\n",
        "    },\n",
        "    \"classifier_type\": \"linear\",\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.005,\n",
        "        \"momentum\": 0.9\n",
        "    },\n",
        "    \"dataset_params\": {\n",
        "        \"batch_size\": 256,\n",
        "        \"use_balanced_sampler\": True,\n",
        "        \"samples_per_class\": 32\n",
        "    }\n",
        "}\n",
        "module = CIFAR10Module(config)\n",
        "logger = pl.loggers.TensorBoardLogger(\"./logs\", name='triplet')\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    logger=logger,\n",
        "    log_every_n_steps=10,\n",
        "    max_epochs=10\n",
        ")\n",
        "trainer.fit(module)\n",
        "trainer.test()"
      ],
      "metadata": {
        "id": "2EGB3zLiPOrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 4. Spherical Embeddings.\n",
        "Реализовать CosFace:\n",
        "\\begin{equation}\n",
        "L_{\\text{CosFace}}=\\frac{1}{N} \\sum_i-\\log \\frac{e^{s\\left(\\cos \\left(\\theta_{y_i, i}\\right)-m\\right)}}{e^{s\\left(\\cos \\left(\\theta_{y_i, i}\\right)-m\\right)}+\\sum_{j \\neq y_i} e^{s \\cos \\left(\\theta_{j, i}\\right)}}\n",
        "\\end{equation}\n",
        "Предлагается использовать заготовку класса `CosFaceClassifier`. Тест в той же ячейке. Рекомендую один раз выписать полученные логиты руками для закрепления материала.\n",
        "\n",
        "**Советы**\n",
        "\n",
        "1. Обратите внимание, что необходимый лосс получится, если передать в `CrossEntropyLoss` $s\\left(\\cos \\left(\\theta_{y_i, i}\\right)-m\\right)$ и $s \\cos \\left(\\theta_{j, i}\\right)$ в качестве логитов.\n",
        "\n",
        "2. Вам с большой вероятностью потребуются функцию `TORCH.NN.FUNCTIONAL.ONE_HOT`. Посмотрите документацию."
      ],
      "metadata": {
        "id": "4WLAXncLv5SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"dim\": 3,\n",
        "    \"criterion_type\": \"ce\",\n",
        "    \"classifier_type\": \"cosface\",\n",
        "    \"classifier_params\": {\n",
        "        \"scale\": 64.0,\n",
        "        \"margin\": 0.05\n",
        "    },\n",
        "    \"optimizer_params\": {\n",
        "        \"lr\": 0.001,\n",
        "        \"momentum\": 0.9\n",
        "    },\n",
        "    \"dataset_params\": {\n",
        "        \"batch_size\": 64,\n",
        "    }\n",
        "}\n",
        "module = CIFAR10Module(config)\n",
        "logger = pl.loggers.TensorBoardLogger(\"./logs\", name='cosface')\n",
        "trainer = pl.Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    logger=logger,\n",
        "    log_every_n_steps=10,\n",
        "    max_epochs=10\n",
        ")\n",
        "trainer.fit(module)\n",
        "trainer.test()"
      ],
      "metadata": {
        "id": "ZoP5HlnaS0cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 5*. Повышаем размерности.\n",
        "\n",
        "На практике эмбеддинги размерности 2 практически не используются. В реальных приложениях размерности начинаются от 128. Давайте посмотрим, как ведут себя модели при этих размерностях, и обсудим результаты."
      ],
      "metadata": {
        "id": "pO31AF7mtyHW"
      }
    }
  ]
}