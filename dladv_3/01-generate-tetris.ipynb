{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "ROOT = \"train\"\n",
    "\n",
    "IMAGE_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6805d",
   "metadata": {},
   "source": [
    "# Данные\n",
    "Создадим корпус картинок с фигурами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_rectangle(image, x, y, block_size, color):\n",
    "    image[y:y + block_size, x:x + block_size] = color\n",
    "    \n",
    "def nested_rectangle(image, x, y, block_size, color):\n",
    "    b = 1\n",
    "    image[y:y + block_size, x:x + block_size] = color\n",
    "    image[y + b:y + block_size - b, x + b:x + block_size - b] = color.clip(max=200) + 55\n",
    "    \n",
    "    \n",
    "STYLES = [\n",
    "    flat_rectangle,\n",
    "    nested_rectangle\n",
    "]\n",
    "\n",
    "\n",
    "BLOCKS = [\n",
    "    [[1, 0, 0],\n",
    "     [1, 1, 1]],\n",
    "    [[1, 1, 0],\n",
    "     [0, 1, 1]],\n",
    "    [[1, 1, 1, 1]],\n",
    "    [[0, 1, 0],\n",
    "     [1, 1, 1]],\n",
    "    [[1, 1],\n",
    "     [1, 1]],\n",
    "]\n",
    "\n",
    "\n",
    "def draw(block, image_size=32, rotate=False):\n",
    "    color = colorsys.hsv_to_rgb(random.random(), random.random() * 0.5 + 0.5, 1)\n",
    "    color = np.asarray([255 * c for c in color], dtype=np.uint8)\n",
    "    block = np.asarray(block)\n",
    "    style = random.choice(STYLES)\n",
    "    if random.random() > 0.5:\n",
    "        block = np.fliplr(block)\n",
    "    if random.random() > 0.5:\n",
    "        block = np.flipud(block)\n",
    "    if random.random() > 0.5:\n",
    "        block = block.T\n",
    "    max_dim = max(block.shape[0], block.shape[1])\n",
    "    image = np.zeros((image_size, image_size, 3), dtype=np.uint8)\n",
    "    block_size = image_size // max_dim  # random.randint(image_size // 8, image_size // max_dim)\n",
    "    width = block.shape[1] * block_size\n",
    "    height = block.shape[0] * block_size\n",
    "    x_offset = random.randint(0, image_size - width)\n",
    "    y_offset = random.randint(0, image_size - height)\n",
    "    for i, row in enumerate(block):\n",
    "        for j, filled in enumerate(row):\n",
    "            if not filled:\n",
    "                continue\n",
    "            x = x_offset + j * block_size\n",
    "            y = y_offset + i * block_size\n",
    "            style(image, x, y, block_size, color)\n",
    "    image = Image.fromarray(image)\n",
    "    if rotate:\n",
    "        angle = random.random() * 360\n",
    "        image = image.rotate(angle, center=(image_size // 2, image_size // 2),\n",
    "                             resample=2)\n",
    "    return image\n",
    "\n",
    "plt.imshow(draw(random.choice(BLOCKS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None, image_size=IMAGE_SIZE, n=2 ** 14):\n",
    "        super().__init__()\n",
    "        self._n = n\n",
    "        self._transform = transform\n",
    "        self._image_size = image_size\n",
    "        \n",
    "    @property\n",
    "    def image_size(self):\n",
    "        return self._image_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = draw(random.choice(BLOCKS), image_size=self._image_size)\n",
    "        if self._transform is not None:\n",
    "            image = self._transform(image)\n",
    "        return image\n",
    "\n",
    "dataset = TetrisDataset()\n",
    "plt.imshow(dataset[len(dataset) // 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5edd562",
   "metadata": {},
   "source": [
    "# Реализуем простую модель, похожую на DCGAN\n",
    "![DCGAN](dcgan.png \"DCGAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1dd0b",
   "metadata": {},
   "source": [
    "**Задание 1.** Предлагается реализовать модель генератора. На вход генератор принимает тензор шума размера (BatchSize, HiddenSize, 1, 1). На выходе генерируется тензор изображений размера (BatchSize, 3, 32, 32). Предлагается использовать ConvTranspose2d, BatchNorm2d, ReLU и Tanh активацию на выходе.\n",
    "\n",
    "ConvTranspose предлагается делать с ядром размера 4. ReLU можно сделать inplace для ускорения.\n",
    "\n",
    "Размеры тензоров на промежуточных слоях должны иметь следующую последовательность:\n",
    "\n",
    "(B, 64, 4, 4)\n",
    "\n",
    "(B, 32, 8, 8)\n",
    "\n",
    "(B, 16, 16, 16)\n",
    "\n",
    "(B, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super().__init__()\n",
    "        assert image_size == 32\n",
    "        self._hidden_size = 16\n",
    "        final_channels = 16\n",
    "        self.model = torch.nn.Sequential(\n",
    "            ### Ваш код здесь.\n",
    "            \n",
    "            ### Конец вашего кода.\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch_size_or_noise):\n",
    "        if isinstance(batch_size_or_noise, torch.Tensor):\n",
    "            # Input is a noise tensor with shape (B, H, 1, 1).\n",
    "            noise = batch_size_or_noise\n",
    "        else:\n",
    "            # Input is batch size.\n",
    "            batch_size = batch_size_or_noise\n",
    "            device = next(iter(self.parameters())).device\n",
    "            noise = torch.randn(batch_size, self._hidden_size, 1, 1, device=device)\n",
    "        return self.model(noise)\n",
    "    \n",
    "    \n",
    "def num_parameters(model):\n",
    "    n = sum(p.numel() for p in model.parameters())\n",
    "    return n\n",
    "\n",
    "\n",
    "def get_tensor_shapes(model, x):\n",
    "    sizes = []\n",
    "    for layer in model:\n",
    "        x = layer(x)\n",
    "        if hasattr(layer, \"kernel_size\"):\n",
    "            sizes.append(x.shape[1:])\n",
    "    return sizes\n",
    "\n",
    "\n",
    "# Проверки.\n",
    "generator = Generator(image_size=dataset.image_size)\n",
    "shapes_gt = [(64, 4, 4), (32, 8, 8), (16, 16, 16), (3, 32, 32)]\n",
    "for shape, shape_gt in zip(get_tensor_shapes(generator.model, torch.randn(5, 16, 1, 1)), shapes_gt):\n",
    "    assert shape == shape_gt\n",
    "assert isinstance(generator.model[-1], torch.nn.Tanh)\n",
    "print(generator, get_tensor_shapes(generator.model, torch.randn(5, 16, 1, 1)))\n",
    "print(num_parameters(generator), generator(5).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865541f7",
   "metadata": {},
   "source": [
    "**Задание 2.** Предлагается реализовать модель дискриминатора. На вход дискриминатор принимает тензор изображений размера (BatchSize, 3, 32, 32). На выходе генерируется тензор логитов размера (BatchSize, 1, 1, 1). Предлагается использовать Conv2d, BatchNorm2d и LeakyReLU активацию. Сигмоиду к выходам применять не нужно.\n",
    "\n",
    "Свертки предлагается делать с ядром размера 4. LeakyReLU можно сделать inplace для ускорения.\n",
    "\n",
    "Размеры тензоров на промежуточных слоях должны иметь следующую последовательность:\n",
    "\n",
    "(B, 16, 16, 16)\n",
    "\n",
    "(B, 32, 8, 8)\n",
    "\n",
    "(B, 64, 4, 4)\n",
    "\n",
    "(B, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        assert image_size == 32\n",
    "        init_channels = 16\n",
    "        self.model = torch.nn.Sequential(\n",
    "            ### Ваш код здесь.\n",
    "            \n",
    "            ### Конец вашего кода.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.model(x).squeeze()\n",
    "        return logits\n",
    "\n",
    "discriminator = Discriminator(image_size=dataset.image_size)\n",
    "shapes_gt = [(16, 16, 16), (32, 8, 8), (64, 4, 4), (1, 1, 1)]\n",
    "for shape, shape_gt in zip(get_tensor_shapes(discriminator.model, torch.randn(5, 3, 32, 32)), shapes_gt):\n",
    "    assert shape == shape_gt\n",
    "print(get_tensor_shapes(discriminator.model, torch.randn(5, 3, 32, 32)))\n",
    "print(discriminator)\n",
    "print(num_parameters(discriminator), discriminator(generator(5)).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072aa87",
   "metadata": {},
   "source": [
    "# Тренировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c706836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xent(logits, is_real, smooth=0.2):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    label = 1 - smooth if is_real else smooth\n",
    "    labels = torch.full_like(probs, label)\n",
    "    return torch.nn.functional.binary_cross_entropy(probs, labels, reduction=\"none\")\n",
    "\n",
    "\n",
    "def mse(logits, is_real):\n",
    "    return (logits - is_real).square()\n",
    "\n",
    "\n",
    "def relu(logits, is_real):\n",
    "    if is_real:\n",
    "        return torch.clip(1 - logits, min=0)\n",
    "    else:\n",
    "        return torch.clip(logits, min=0)\n",
    "    \n",
    "    \n",
    "criterion = relu\n",
    "\n",
    "logits = torch.linspace(-1, 2, 100)\n",
    "plt.plot(logits, criterion(logits, 1), label=\"Real\")\n",
    "plt.plot(logits, criterion(logits, 0), label=\"Fake\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3dca67",
   "metadata": {},
   "source": [
    "**Задание 3.** Реализовать training_step.\n",
    "\n",
    "Используйте функцию criterion(logits, labels), которая вычисляет лосс.\n",
    "\n",
    "Используйте self._generator(batch_size) для применения генератора и self._discriminator(images) для дискриминатора.\n",
    "\n",
    "При оценке лосса дискримнатора стоит отключить пробрасывание градиентов в генератор (метод detach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "\n",
    "class Module(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "        self._dataset = TetrisDataset(transform=transform)\n",
    "        self._generator = Generator(image_size=self._dataset.image_size)\n",
    "        self._discriminator = Discriminator(image_size=self._dataset.image_size)\n",
    "        self._generator.apply(weights_init)\n",
    "        self._discriminator.apply(weights_init)\n",
    "        \n",
    "    def forward(self, batch_size, detach_generator=False):\n",
    "        images = self._generator(batch_size)\n",
    "        if detach_generator:\n",
    "            images = images.detach()\n",
    "        logits = self._discriminator(images)\n",
    "        return images, logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx=0):\n",
    "        if optimizer_idx == 0:\n",
    "            # Вычислим лосс генератора.\n",
    "            \n",
    "            ### Ваш код здесь.\n",
    "            loss = ...\n",
    "            ### Конец вашего кода.\n",
    "            \n",
    "            self.log(\"g_loss\", loss, prog_bar=True)\n",
    "        if optimizer_idx == 1:\n",
    "            # Вычислим лосс дискриминатора.\n",
    "            \n",
    "            ### Ваш код здесь.\n",
    "            real_loss = ...\n",
    "            fake_loss = ...\n",
    "            ### Конец вашего кода.\n",
    "            \n",
    "            self.log(\"d_r_loss\", real_loss, prog_bar=True)\n",
    "            self.log(\"d_f_loss\", fake_loss, prog_bar=True)\n",
    "            loss = real_loss + fake_loss\n",
    "        return loss\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        g_optimizer = torch.optim.Adam(self._generator.parameters(),\n",
    "                                       lr=0.01, betas=(0.5, 0.999))\n",
    "        d_optimizer = torch.optim.Adam(self._discriminator.parameters(),\n",
    "                                       lr=0.01, betas=(0.5, 0.999))\n",
    "        return [g_optimizer, d_optimizer], []\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        loader = torch.utils.data.DataLoader(self._dataset, batch_size=128,\n",
    "                                             shuffle=True, drop_last=True)\n",
    "        return loader\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        with torch.no_grad():\n",
    "            generated, _ = self(16)\n",
    "            grid = make_grid(generated, padding=0, normalize=True, nrow=4)\n",
    "        image = (grid.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "        imsave(\"grid.jpg\", image)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "def train(module):\n",
    "    pl.seed_everything(0)\n",
    "    trainer = pl.Trainer(default_root_dir=ROOT, accelerator=\"auto\", max_epochs=100)\n",
    "    trainer.fit(module)\n",
    "\n",
    "    \n",
    "module = Module()\n",
    "train(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa36eb",
   "metadata": {},
   "source": [
    "**Домашнее задание (без оценки)**. Попробуйте добавить feature matching loss, self-attention или дополнительные головы дискриминатора. Попробуйте также учить дольше или подобрать параметры optimizer. Попробуйте добавить голову классификации типа фигурки на выход генератора. Попробуйте генерировать изображения большего размера (128x128). Попробуйте добавить повороты в исходный датасет.\n",
    "\n",
    "Присылайте картинки в чат группы)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
